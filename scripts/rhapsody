#!/usr/bin/env python3
import os
import time
import click
import datetime
import pandas as pd
import numpy as np
from tqdm import tqdm
from decimal import Decimal
from biom import load_table, Table
from biom.util import biom_open
from skbio.stats.composition import clr, centralize, closure
from skbio.stats.composition import clr_inv as softmax
from skbio import OrdinationResults
from scipy.stats import entropy, spearmanr
from scipy.sparse import csr_matrix

from rhapsody.mmvec import MMvec
from rhapsody.util import split_tables, format_params
from rhapsody.train import train_cooccurrence


@click.group()
def rhapsody():
    pass


@rhapsody.command()

@click.option('--microbe-file',
              help='Input microbial abundances')
@click.option('--metabolite-file',
              help='Input metabolite abundances')

@click.option('--metadata-file', default=None,
              help='Input sample metadata file')
@click.option('--training-column',
              help=('Column in the sample metadata specifying which '
                    'samples are for training and testing.'),
              default=None)
@click.option('--num-testing-examples',
              help=('Number of samples to randomly select for testing'),
              default=10)
@click.option('--min-feature-count',
              help=('Minimum number of samples a microbe needs to be observed '
                    'in order to not filter out'),
              default=10)
@click.option('--epochs',
              help=('Number of epochs to train, one epoch represents the '
                    'number of samples to process an entire dataset.'), default=10)
@click.option('--batch-size',
              help='Number of samples to analyze per iteration.', default=10)
@click.option('--subsample-size',
              help='Number of sequences to analyze per sample.', default=100)
@click.option('--latent-dim',
              help=('Dimensionality of shared latent space. '
                    'This is analogous to the number of PC axes.'),
              default=3)
@click.option('--arm-the-gpu', is_flag=True,
              help=('Enables GPU support'),
              default=False)
@click.option('--learning-rate',
              help=('Gradient descent learning rate.'),
              default=1e-1)
@click.option('--beta1',
              help=('Gradient decay rate for first Adam momentum estimates'),
              default=0.9)
@click.option('--beta2',
              help=('Gradient decay rate for second Adam momentum estimates'),
              default=0.95)
@click.option('--checkpoint-interval',
              help=('Number of seconds before a storing a checkpoint.'),
              default=1000)
@click.option('--summary-interval',
              help=('Number of seconds before a storing a summary.'),
              default=1000)
@click.option('--summary-dir', default='summarydir',
              help='Summary directory to save cross validation results.')
@click.option('--model-output', default=None,
              help=('Model parameter file containing microbe-metabolite '
                    'interaction parameters.'))
@click.option('--ordination-output', default=None,
              help=('Ordination output to visualize the microbe-metabolite '
                    'embeddings. '))
def mmvec(microbe_file, metabolite_file,
          metadata_file, training_column,
          num_testing_examples, min_feature_count,
          epochs, batch_size, subsample_size,
          latent_dim, arm_the_gpu,
          learning_rate, beta1, beta2,
          checkpoint_interval, summary_interval,
          summary_dir, model_output, ordination_output):

    microbes = load_table(microbe_file)
    metabolites = load_table(metabolite_file)

    if metadata_file is not None:
        metadata = pd.read_table(metadata_file, index_col=0)
    else:
        metadata = None

    res = split_tables(
        microbes, metabolites,
        metadata=metadata, training_column=training_column,
        num_test=num_testing_examples,
        min_samples=min_feature_count)

    (train_microbes_df, test_microbes_df,
     train_metabolites_df, test_metabolites_df) = res

    # filter out low abundance microbes
    microbe_ids = microbes.ids(axis='observation')
    metabolite_ids = metabolites.ids(axis='observation')

    params = []

    sname = '_'.join(['log_PC(%d)' % latent_dim,
                      'samp(%d)' % batch_size,
                      'sub(%d)' % subsample_size,
                      'lr(%s)' % "{:.2E}".format(Decimal(learning_rate)),
                      'beta1(%.2f)' % beta1,
                      'beta2(%.2f)' % beta2])

    sname = os.path.join(summary_dir, sname)

    trainX = csr_matrix(train_microbes_df.values)
    testX = csr_matrix(test_microbes_df.values)
    trainY = train_metabolites_df.values
    testY = test_metabolites_df.values

    n, d1 = trainX.shape
    n, d2 = trainY.shape

    if arm_the_gpu:
        # pick out the first GPU
        device_name='cuda'
    else:
        device_name='cpu'
    microbe_total = np.sum(train_microbes_df.values)
    model = MMvec(num_samples=n, num_microbes=d1, num_metabolites=d2,
                  microbe_total=microbe_total, latent_dim=latent_dim,
                  batch_size=batch_size, subsample_size=subsample_size
    )
    # if device_name=='cuda':
    model = model.to(device=device_name)

    fitted_model = model.fit(
        trainX, trainY, testX, testY,
        epochs=epochs, learning_rate=learning_rate,
        beta1=beta1, beta2=beta2,
        summary_interval=summary_interval,
        checkpoint_interval=checkpoint_interval,
        device=device_name, save_path=sname)

    # now extract the model weights and save them to disk
    def extract(x):
        return x.detach().cpu().numpy()
    mu_u = extract(fitted_model.encoder.embedding.weight)
    mu_ub = extract(fitted_model.encoder.bias.weight).reshape(-1, 1)
    mu_v = extract(fitted_model.decoder.mean.weight)
    mu_vb = extract(fitted_model.decoder.mean.bias).reshape(-1, 1)
    std_u = np.exp(0.5 * extract(fitted_model.encoder.embedding_var.weight))
    std_ub = np.exp(0.5 *
        extract(fitted_model.encoder.bias_var.weight)
    ).reshape(-1, 1)
    std_v = np.exp(0.5 * extract(fitted_model.decoder.var.weight))
    std_vb = np.exp(0.5 * extract(fitted_model.decoder.var.bias)).reshape(-1, 1)

    otu_ids = list(train_microbes_df.columns)
    ms_ids = list(train_metabolites_df.columns)
    pc_ids = ['PC%d' % i for i in range(mu_u.shape[1])]

    Uparam = format_params(mu_u, std_u, pc_ids, otu_ids, 'microbe')
    Vparam = format_params(mu_v, std_v, pc_ids, ms_ids, 'metabolite')
    df = pd.concat(
        (
            Uparam, Vparam,
            format_params(mu_ub, std_ub, ['bias'], otu_ids, 'microbe'),
            format_params(mu_vb, std_vb, ['bias'], ms_ids, 'metabolite')
        ), axis=0)

    df.to_csv(model_output)

    # extract the model parameters and save to biplot
    U = pd.pivot(Uparam, index='feature_id', columns='axis', values='mean')
    V = pd.pivot(Vparam, index='feature_id', columns='axis', values='mean')

    def _center(x):
        hmean = x.mean(axis=0)
        y = (x - hmean)
        y = y - y.mean(axis=1).values.reshape(-1, 1)
        return y

    U = _center(U[pc_ids])
    V = _center(V[pc_ids])

    s = np.linalg.svd(U.values)[1]
    eigvals = pd.Series(s**2, index=pc_ids)

    res = OrdinationResults('MultiomicsBiplot', 'Multiomics Biplot',
                            samples=U, features=V,
                            eigvals = eigvals,
                            proportion_explained = eigvals / eigvals.sum())
    res.write(ordination_output)


if __name__ == '__main__':
    rhapsody()
